{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17c18ad-3052-4859-8932-d72ccb41df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from torchtext.datasets import WikiText103\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from spacy.cli.download import download\n",
    "import time\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "\n",
    "from io_utils import *\n",
    "from toxic_suppression_wrapper import GPT2Wrapper\n",
    "from toxicity_scoring import toxicity_scoring\n",
    "from perplexity import compute_ppl\n",
    "\n",
    "API_KEY = \"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-medium\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "wrapper = GPT2Wrapper(model_name = \"gpt2-medium\", use_cuda = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c64dd78-4d6c-493e-a788-c4131511ca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE LAYER 13 IDX 1852\n",
      "[(' transparency', 0.7804232), (' disclosure', 0.08604208), (' clearer', 0.031260245), (' humility', 0.018021714), ('parency', 0.01392095), ('iquette', 0.013061815), (' better', 0.006321151), (' modesty', 0.0062694233), (' transparent', 0.004169269), (' safer', 0.0038504757)]\n",
      "\n",
      "\n",
      "VALUE LAYER 14 IDX 72\n",
      "[(' reconc', 0.9182025), (' respectful', 0.029803287), (' healthy', 0.008752354), (' taxp', 0.007006365), (' gracious', 0.0039775595), (' decent', 0.003406394), (' fair', 0.0031924762), (' modesty', 0.0018224006), (' peacefully', 0.0016074623), (' peaceful', 0.0014397277)]\n",
      "\n",
      "\n",
      "VALUE LAYER 14 IDX 1394\n",
      "[('safe', 0.55344427), ('cart', 0.11201968), ('course', 0.064264335), (' Compact', 0.02360836), ('respect', 0.02322706), (' COUR', 0.019045586), ('safety', 0.01884989), (' neither', 0.016840337), (' Safe', 0.011104363), (' apologize', 0.010102618)]\n",
      "\n",
      "\n",
      "VALUE LAYER 15 IDX 215\n",
      "[(' acceptance', 0.17209195), (' refere', 0.12844867), ('Accept', 0.07810877), ('Relations', 0.06570935), (' promises', 0.055129457), (' Jub', 0.038198203), (' persistence', 0.023688573), (' assertions', 0.023370389), (' relational', 0.019203763), ('accept', 0.01874153)]\n",
      "\n",
      "\n",
      "VALUE LAYER 16 IDX 461\n",
      "[('should', 0.8848216), (' should', 0.113595076), (' ought', 0.00068675523), (' SHOULD', 0.00025834155), (' MUST', 0.00021377351), (' wisely', 0.00015655466), (' safely', 0.00013167493), (' Should', 3.1968335e-05), (' urgently', 3.1195705e-05), (' shouldn', 3.035402e-05)]\n",
      "\n",
      "\n",
      "VALUE LAYER 16 IDX 3208\n",
      "[(' peaceful', 0.41999495), (' stable', 0.14593558), (' satisfactory', 0.04235941), (' good', 0.038141813), (' trustworthy', 0.03358423), (' safe', 0.020019896), (' reassured', 0.019764626), (' credibility', 0.018199418), ('Safe', 0.01630799), (' impartial', 0.014914288)]\n",
      "\n",
      "\n",
      "VALUE LAYER 16 IDX 4060\n",
      "[(' proper', 0.53371435), (' Proper', 0.20203568), (' properly', 0.16917071), (' wisely', 0.037420776), (' correct', 0.03168829), (' sensible', 0.004102614), (' appropriately', 0.0039902017), (' restraint', 0.0028990908), (' moder', 0.002696694), (' balanced', 0.0018932042)]\n",
      "\n",
      "\n",
      "VALUE LAYER 17 IDX 2920\n",
      "[(' thank', 0.95024586), (' thanks', 0.044266775), (' THANK', 0.0045430916), (' apologies', 0.00031247997), (' Thank', 0.00023761527), ('thank', 0.00023511855), ('Thank', 8.6941865e-05), (' apologise', 2.5975052e-05), (' apologize', 1.4602401e-05), (' hereby', 9.264447e-06)]\n",
      "\n",
      "\n",
      "VALUE LAYER 18 IDX 1890\n",
      "[(' thanks', 0.9999907), (' thank', 4.6997047e-06), (' Thanks', 4.6380815e-06), ('thanks', 6.147385e-08), (' THANK', 4.88339e-09), ('Thanks', 2.0490927e-09), (' Thank', 2.1426347e-10), ('Thank', 1.0837235e-11), ('thank', 1.7713448e-12), (' congratulations', 1.3718622e-13)]\n",
      "\n",
      "\n",
      "VALUE LAYER 22 IDX 3769\n",
      "[(' fit', 0.4611976), (' free', 0.25517157), ('legal', 0.14665267), ('leg', 0.047011968), (' und', 0.0280762), (' Free', 0.011328501), ('pless', 0.009235407), (' sound', 0.0050243745), ('untary', 0.0038638238), (' Unreal', 0.0033876873)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_toxic_values = {\n",
    "    13: [1852],\n",
    "    14: [72, 1394],\n",
    "    15: [215],\n",
    "    16: [461, 3208, 4060],\n",
    "    17: [2920],\n",
    "    18: [1890],\n",
    "    22: [3769]\n",
    "}\n",
    "\n",
    "for layer in non_toxic_values.keys():\n",
    "    for idx in non_toxic_values[layer]:\n",
    "        print(\"VALUE LAYER \" + str(layer) + \" IDX \" + str(idx))\n",
    "        print(wrapper.project_value_to_vocab(layer, idx))\n",
    "        print(\"\\n\")\n",
    "\n",
    "with open(\"non_toxic_values.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(non_toxic_values, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c101db-8dc4-4743-8c1a-6492a0a2cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.read_pickle(\"non_toxic_values.pickle\")\n",
    "wrapper = GPT2Wrapper(model_name = \"gpt2-medium\", use_cuda = True)\n",
    "ppl_debiased, ppl_regular = compute_ppl(tokenizer, wrapper, values_per_layer = values, \n",
    "                                        coef_value = 3, \n",
    "                                        use_cuda = True)\n",
    "\n",
    "\"\"\"\n",
    "Above lines equivalent to:\n",
    "\n",
    "python3 perplexity.py --model_name gpt2-medium \\\n",
    "                      --values_filepath non_toxic_values.pickle \\\n",
    "                      --coef_value 3 \\\n",
    "                      --use_cuda\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acc8f0-d7c2-4998-b93a-1243a2921621",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.read_pickle(\"non_toxic_values.pickle\")\n",
    "wrapper = GPT2Wrapper(model_name = \"gpt2-medium\", use_cuda = True)\n",
    "\n",
    "toxicity_scoring(prompts_filename = \"prompts.jsonl\", \n",
    "                 output_dir = \"toxicity-suppression-results\",\n",
    "                 api_key = API_KEY,\n",
    "                 wrapper = wrapper, \n",
    "                 values_per_layer = values,\n",
    "                 challenging_only = True,\n",
    "                 coef_value = 3,\n",
    "                 mode = \"toxic-suppr\",\n",
    "                 max_prompts = 100)\n",
    "\n",
    "\"\"\"\n",
    "Above lines equivalent to:\n",
    "\n",
    "python3 toxicity_scoring.py --prompts_filename prompts.jsonl \\\n",
    "                            --output_dir toxicity-suppresion-results \\\n",
    "                            --api_key <API_KEY> \\\n",
    "                            --model_name gpt2-medium \\\n",
    "                            --values_filepath non_toxic_values.pickle \\\n",
    "                            --challenging_only \\\n",
    "                            --coef_value 3 \\\n",
    "                            --mode toxic-suppr \\\n",
    "                            --max_prompts 100 \\\n",
    "                            --use_cuda\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6004dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = GPT2Wrapper(model_name = \"gpt2-medium\", use_cuda = True)\n",
    "\n",
    "toxicity_scoring(prompts_filename = \"prompts.jsonl\", \n",
    "                 output_dir = \"toxicity-suppression-results\",\n",
    "                 api_key = API_KEY,\n",
    "                 wrapper = wrapper, \n",
    "                 challenging_only = True,\n",
    "                 mode = \"word-filter\",\n",
    "                 max_prompts = 100)\n",
    "\n",
    "\"\"\"\n",
    "Above lines equivalent to:\n",
    "\n",
    "python3 toxicity_scoring.py --prompts_filename prompts.jsonl \\\n",
    "                            --output_dir toxicity-suppresion-results \\\n",
    "                            --api_key <API_KEY> \\\n",
    "                            --model_name gpt2-medium \\\n",
    "                            --challenging_only \\\n",
    "                            --mode word-filter \\\n",
    "                            --max_prompts 100 \\\n",
    "                            --use_cuda\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
